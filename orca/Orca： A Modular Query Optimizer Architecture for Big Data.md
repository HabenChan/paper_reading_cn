## **摘要**

数据管理系统中分析查询处理的性能主要取决于系统查询优化器的能力。增加的数据量和处理复杂的分析查询的高度兴趣，已促使Pivotal构建一个新的查询优化器。

在本文中，我们提出了Orca的体系结构，新的查询优化器为所有关键数据管理产品，包括关键 Greenplum数据库和关键HAWQ。Orca 是一项综合开发，将最先进的查询优化技术与自己的原创研究相结合，从而形成模块化和便携式优化器架构。

除了描述总体架构外，我们还将重点介绍几个独特的特性，并与其他系统进行性能比较。

## **1. 引言**

大数据让人们对查询重新产生了兴趣 作为新型数据管理系统的优化 已经在前所未有的规模方面突破了极限能力、可用性和处理能力，这使得大型数据集包含数百个易于分析 TB 甚至 PB 级数据 通过SQL 或类似 SQL 的接口。好的优化器和平庸的优化器之间的差异一直都是众所周知的。 但随着数据量的增加这些系统必须处理放大的优化错误并比以往更强调查询优化的重要性 。

尽管在这一领域有大量的研究，但商业和开源项目中的大多数现有查询优化器仍然主要基于商业数据库开发早期的技术，并且经常容易产生次优结果。

意识到研究和实际实现之间的巨大差距，我们已经着手设计一个既能满足当前需求，又能保证未来发展有足够空间的架构。

在本文中，我们描述了 Orca，我们最近在 Greenplum/Pivotal 的研究和开发工作的结果。Orca是一个最先进的查询优化器，专门为苛刻的分析工作负载而设计。它区别于其他优化器在几个重要的方面:

- 模块化。使用高度可扩展的元数据抽象和系统描述，Orca不再像传统的优化器那样局限于特定的主机系统。相反，它可以通过元数据提供商 SDK支持的插件快速移植到其他数据管理系统。
- 可扩展性。通过将查询的所有元素及其优化表示为具有同等地位的一等公民，Orca避免了多阶段优化的陷阱，即某些优化是事后才处理的。众所周知，多阶段优化器很难扩展，因为新的优化或查询构造通常与之前设置的阶段边界不匹配。
- 多核准备就绪。 Orca 部署了高效的多核心感知调度程序，分配单独的细跨多个核心的粒度优化子任务 加快优化过程。
- 可验证性。 Orca 有特殊规定来确定 内置级别的正确性和性能 机制。 除了改进工程实践之外， 这些工具能够以高配置实现快速开发 并导致双方的周转时间缩短 新功能以及错误修复。
- 性能。Orca比我们之前的系统有了很大的改进，在很多情况下提供了10到1000倍的查询速度。

我们将描述Orca的架构，并重点介绍其设计所支持的一些高级功能。我们提供各种组件的蓝图，以及我们为实现这个项目所倡导和部署的工程实践的细节。最后，在 TPC-DS基准测试的基础上，给出了 Orca 与其他系统的性能对比结果。特别地，我们将重点放在为开源领域做出贡献的查询处理系统上。

![img](https://pic1.zhimg.com/80/v2-de530e8996dbd9fd75638d4ecbb1ae48_720w.webp)

本文的其余部分组织如下。我们在第2节中给出了计算体系结构的初步介绍。在第3节中，我们将介绍 Orca 的架构并描述它的组件。第 4节介绍查询优化工作流。第 5节描述了 Orca 如何与后端数据库系统交换元数据。我们在第6节中描述了我们为维护可验证查询优化器而构建的工具。第7节介绍了我们的实验研究，然后在第8节讨论了相关工作。我们在第9节对本文进行了总结。

## **2. 准备工作**

我们初步介绍了大规模并行处理数据库(第2.1 节)和Hadoop查询引擎(第2.2节)。

### **2.1 大规模并行处理**

Pivotal的Greenplum数据库(GPDB)是一个大规模并行处理(MPP)分析数据库。GPDB采用无共享计算体系结构，具有两个或多个协作处理器。每个处理器都有自己的内存、操作系统和磁盘。GPDB利用这种高性能的系统架构来分配pb级数据仓库的负载，并并行地使用系统资源来处理给定的查询。

图1显示了GPDB的高层架构。大量数据的存储和处理是通过在多个服务器或主机上分配负载来处理的，以创建一个单独的数据库数组，所有这些数据库一起工作 来呈现单个数据库映像。master 是GPDB的入口点，客户端在这里连接并提交SQL语句。主数据库与其他称为segments的数据库实例协调工作，以处理数据处理和存储。当一个查询被提交给主服务器时，它会被优化并被分解成更小的组件，这些组件被分配到各个部分，以共同传递最终的结果。互连层是负责segments间进程间通信的网络层。互连使用标准的千兆以太网交换结构。

在执行查询时，数据可以以多种方式分布到段中，包括散列分布(基于某些散列函数将元组分布到段中)、复制分布(表的完整副本存储在每个段中)和单例分布(单例分布)。在这里，整个分布式表从多个段收集到单个主机(通常是主机)。

### **2.2 SQL on Hadoop**

在Hadoop上处理分析查询变得越来越流行。最初，查询被表示为MapReduce 任务，Hadoop的吸引力被归因于其可伸缩性和容错性。尽管在MapReduce 中编码、手工优化和维护复杂的查询非常困难，因此类似 sql 的声明性语言，如Hive，都是在Hadoop上开发的。HiveSQL查询被编译成 MapReduce 任务，由 Hadoop 执行。HiveQL加速了复杂查询的编码，但也明显表明Hadoop生态系统中需要一个优化器，因为编译的 MapReduce 任务表现出较差的性能。

为了应对这一挑战，Pivotal引入了HAWQ，这是一个基于HDFS的大规模并行sql兼容引擎。HAWQ以Orca为核心，设计高效的查询计划，最大限度地降低Hadoop集群中访问数据的成本。HAWQ的架构将创新的、最先进的、基于成本的优化器与 Hadoop的可伸缩性和容错性结合起来，以实现pb级数据的交互处理。

最 近 ，包 括 Cloudera 的 Impala和 Facebook 的Presto在内的其他一些努力，都引入了新的优化器来支持Hadoop上的SQL处理。目前，这些工作只支持SQL标准特性的一个子集，它们的优化仅限于基于规则的。相比之下，HAWQ有一个成熟的、符合标准的SQL接口和一个基于成本的优化器，这两个特性在 Hadoop 查询引擎中都是前所未有的。我们在第 7节的实验研究中说明了 Orca在将HAWQ与其他Hadoop SQL引擎从功能和性能两个方面区分开来方面所扮演的关键角色。

### **3. ORCA 架构**

Orca 是关键数据管理产品(包括GPDB和HAWQ)的新查询优化器。Orca是一个基于Cascades 优化框架的现代自顶向下查询优化器。虽然许多Cascades优化器都与它们的主机系统紧密耦合，但Orca的一个独特特性是，它能够作为一个独立的优化器运行在数据库系统之外。这种能力对于使用一个优化器来支持具有不同计算架构(如MPP和Hadoop)的产品至关重要。它还允许在新的查询处理范例(如Hadoop)中利用关系优化的大量遗留问题。此外，将优化器作为一个独立的产品运行可以实现复杂的测试，而不需要通过数据库系统的整体结构。

dxl 要将优化器与数据库系统分离，需要构建一种通信机制来处理查询。Orca 包含一个用于在优化器和数据库系统之间交换信息的框架，称为数据交换语言 (Data Exchange Language, DXL)。该框架使用基于xml的语言对必要的信息进行编码

![img](https://pic4.zhimg.com/80/v2-3acc8030059a43416dfd8046566d8113_720w.webp)

用于通信，例如输入查询、输出计划和元数据。覆盖在DXL上的是一个简单的通信协议，用于发送初始查询结构并检索优化的计划。DXL的一个主要好处是将 Orca 打包为一个独立的产品。

图 2 显示了Orca 和外部数据库系统之间的交互。Orca的输入是一个DXL查询。Orca的输出是一个DXL计划。在优化过程中，可以查询数据库系统的元数据(如表定义)。Orca 通过允许数据库系统注册一个元数据提供商(MDprovider)来抽象元数据访问细节，该提供商负责将元数据在发送到Orca之前序列化到DXL中。元数据还可以从包含以DXL格式序列化的元数据对象的常规文件中使用。

数据库系统需要包含使用/发送DXL格式数据的翻译程序。Query2DXL转换程序将查询解析树转换为DXL查询，而DXL2Plan 转换程序将DXL计划转换为可执行计划。这种翻译器的实现完全是在 Orca之外完成的，这允许多个系统通过提供适当的翻译器来使用Orca。

Orca的架构是高度可扩展的;所有组件都可以单独更换和配置。图 3显示了 Orca的不同组件。我们将这些组件简要描述如下

- **Memo.** 由优化器生成的计划备选方案空间被编码在一个称为Memo的紧凑内存数据结构中。Memo结构由一组称为组的容器组成，每个组包含逻辑上等价的表达式。备忘组捕获查询的不同子目标(例如，表上的过滤器，或连接两个表)。组成员，称为组表达式，以不同的逻辑方式实现组目标(例如，不同的连接顺序)。每个组表达式都是一个将其他组作为其子的操作符。Memo的递归结构允许对大量可能的计划进行压缩编码，如4.1节所示。
- **Search and Job Scheduler.** Orca使用搜索机制在可能的备选方案空间中导航，并确定估计成本最低的方案。搜索机制是由一个专门的作业调度器启用的，它创建依赖的或并行的工作单元来执行查询优化，主要有三个步骤: ①在生成等价逻辑表达式的地方进行探索；②在生成物理计划的地方进行实现； ③在执行所需的物理属性(例如，排序顺序)并对计划替代方案进行成本计算的地方进行优化。我们将在第 4.2节详细讨论优化作业调度。
- **Transformations.** 计划可选方案是通过应用转换规则生成的，转换 规 则 可 以 生 成 等 价 的 逻 辑 表 达 式 ( 例 如 ，InnerJoin(A,B)→InnerJoin(B,A))，或者现有表达式的物理实现(例如，Join(A,B)→HashJoin(A,B))。应用转换规则的结果被复制到Memo中，这可能导致创建新组和/或向现有组添加新组表达式。每个转换规则都是一个自包含的组件，可以在Orca配置中显式激活/禁用。
- **Property Enforcement.** Orca包含一个可扩展的框架，用于描述基于正式属性规范的查询需求和计划特征。属性具有不同的类型包括逻辑属性(例如，输出列)、物理属性(例如，排序顺序和数据分布)和标量属性(例如，连接条件中使用的列)。在查询优化期间，每个操作符都可以从其子操作符请求特定的属性。优化后的子计划可以满足其本身所需的属性(例如，IndexScan 计划交付排序数据)，或者需要插入强制执行器(例如，Sort 操作符)来交付所需的属性。该框架允许每个操作符根据子计划的属性和操作符的局部行为来控制执行者的放置。我们将在4.1节中更详细地描述这个框架。
- **Metadata Cache.** 由于元数据(例如，表定义)不经常更改，因此随每个查询传递它会引起开销。Orca 在优化器侧缓存元数据，只有在缓存中不可用或上次加载后发生了变化时才从目录中检索元数据的片段。元数据缓存还从优化器中提取数据库系统细节，这在测试和调试期间特别有用。

gpos为了与可能使用不同 api的操作系统交互，Orca使用了一个称为GPOS的操作系统抽象层。GPOS层为Orca提供了广泛的基础设施，包括内存管理器、并发控制原语、异常处理、文件I/O和同步数据结构。

## **4. 查询优化**

我们在 4.1 节中描述了 Orca 的优化工作流程。然后，我们将在第4.2节中展示如何并行地执行优化过程。

![img](https://pic3.zhimg.com/80/v2-df7dee81ea70187ba8c41c2c73f9db96_720w.webp)

### **4.1优化流程**

我们使用下面的运行示例来说明查询优化工作流程:

```sql
SELECT T1.a FROM T1, T2
WHERE T1.a = T2.b
ORDER BY T1.a;
```

其中，对T1分布进行哈希处理(T1.a)，对T2 分布进行哈希处理(T2.a)(参见第2.1节)。清单1显示了之前的查询在DXL中的表示，其中我们给出了所需的输出列、排序列、数据分布和逻辑查询。元数据(如表和操作符定义)用元数据 id (Mdid)装饰，以便在优化过程中请求进一步的信息。Mdid是由数据库系统标识符、对象标识符和版本号组成的唯一标识符。例如，' 0.96.1.0'引用GPDB版本为' 1.0 '的整数相等操作符。元数据版本用于使经过跨查询修改的缓存元数据对象无效。我们将在第5节中更详细地讨论元数据交换。

DXL查询消息被发送到Orca，在那里它被解析并转换为内存中的逻辑表达式树，该树被复制到Memo中。图4显示了Memo的初始内容。逻辑表达式为两个表和 InnerJoin操作创建了三个组。为了简便起见，我们省略了连接条件。组0称为根组，因为它对应于逻辑表达式的根。逻辑表达式中操作符之间的依赖关系被捕获为组之间的引用。例如，InnerJoin[1,2]将组1和组2称为子组。按照下面的步骤进行优化。

![img](https://pic1.zhimg.com/80/v2-103143d3b66b55ec10abe57c8e3aae5c_720w.webp)

**(1) Exploration.** 生成逻辑等价表达式的转换规则被触发。例如，一个 Join 交换性规则被触发，从 InnerJoin[1,2]中生成InnerJoin[2,1]。探索将新组表达式添加到现有组中，并可能创建新组。Memo结构有一个内置的基于表达式拓扑的重复检测机制，用于检测和消除由不同转换创建的任何重复表达式。

**(2) Statistics Derivation.**

在探索的最后，Memo维护给定查询的完整逻辑空间。Orca 的统计数据派生机制被触发来计算Memo组的统计数据。Orca中的统计对象主要是一组列直方图，用于估算基数和数据倾斜。统计数据的派生发生在紧凑的Memo结构上，以避免扩大搜索空间。

为了为目标组派生统计信息，Orca选择了承诺提供可靠统计信息的组表达式。统计承诺计算是特定于表达式的。例如，具有少量连接条件的InnerJoin表达式比具有大量连接条件的另一个等价的 InnerJoin 表达式更有希望(当生成多个连接顺序时，可能会出现这种情况)。其基本原理是，连接条件的数量越大，估计误差被传播和放大的几率就越大。计算基数估计的置信分数是一项挑战，因为需要在给定表达式的所有节点上聚合置信分数。我们目前正在探索几种方法来计算紧凑Memo结构中的置信度得分。

在目标组中选择最有希望的组表达式后，Orca递归地触发对所选组表达式的子组的统计派生。最后，结合子组的统计对象构造目标组的统计对象。

![img](https://pic3.zhimg.com/80/v2-5ad7121efdb695dc89bb2154b5babcd6_720w.webp)

构造的统计对象被附加到单独的组中，它们可以在优化期间增量地更新(例如，通过添加新的直方图)。这对于保持统计数据派生的成本可控至关重要。

**(3) Implementation.**

创建逻辑表达式的物理实现的转换规则被触发。例如，触发 Get2Scan 规则，从逻辑 Get 中生成物理表Scan。类似地，InnerJoin2HashJoin 和InnerJoin2NLJoin规则被触发来生成哈希和嵌套循环连接实现。

**(4) Optimization.**

在这一步中，财产被强制执行，计划替代方案被计算成本。优化首先向Memo的根组提交一个初始的优化请求，指定查询需求，比如结果分布和排序顺序。向组 g提交一个请求 r，相当于用g中的根物理操作符请求满足 r的最小成本计划。

对于每个传入的请求，每个物理组表达式根据传入的需求和操作符的本地需求将相应的请求传递给子组。在优化过程中，许多相同的请求可能被提交到同一组。Orca将计算得到的请求缓存到一个组哈希表中。只有当传入的请求不存在于组哈希表中时，才会计算它。此外，每个物理组表达式都包含一个本地哈希表，将传入的请求映射到相应的子请求。本地哈希表提供了从Memo中提取物理计划时使用的链接结构，我们将在本节后面展示。

图6显示了正在运行的示例的Memo中的优化请求。初始优化请求为 req. #1: {Singleton, <T1.a>}，它指定查询结果需要根据 T1.a 给出的顺序收集到主服务器。我们还展示了组哈希表，其中每个请求都与以最少的估计成本满足请求的最佳组表达式(GExpr)相关联。黑框表示插入到Memo中的强制操作符，以交付排序顺序和数据分发bution 收 集 操 作 符 将 元 组 从 所 有 段 收 集 到 主 段 GatherMerge操作符从所有段收集排序后的数据到主节点，同时保持排序顺序。redistributionoperator 根据给定参数的哈希值跨段分配元组。

图 7 显示了 req 的优化。 #1 by Inner-HashJoin[1,2]。 对于此请求，替代计划之一 根据连接条件对齐子分布，所以 要连接的元组位于同一位置2。 这样就实现了 通过请求第 1 组的 Hashed(T1.a) 分布以及来自组 2 的散列（T2.b）分布。两组都是要求交付任何排序订单。 child出生后的最佳计划 发现，InnerHashJoin 结合子属性来阻止 挖掘交付的分布和排序顺序。 注意 第 2 组的最佳计划需要将 T2 散列分布在 T2.b，因为T2最初是在T2.a上散列分布的，而 第 1 组的最佳计划是简单扫描，因为 T1 已经 T1.a 上散列分布。

当确定交付的属性不满足初始需求时，必须强制执行未满足的属性。Orca 中的属性强制是一个灵活的框架，它允许每个操作符根据子计划交付的属性和操作符本地行为来定义强制所需属性的行为。例如，如果订单已经由外部子级交付，则保留顺序的NL Join 操作符可能不需要在联接之上强制排序顺序。

执行者被添加到包含正在优化的组表达式的组中。图7显示了满足 req的两个可能的计划。第一，通过property enforcement。左计划对片段上的连接结果进行排序，然后在主节点上对排序后的结果进行收集-合并。正确的计划将片段中的连接结果收集到主节点，然后对它们进行排序。这些不同的备选方案被编码在Memo中，由成本模型来区分它们的成本。

最后，根据优化要求给出的连杆结构，从Memo中提取出最优方案。图 6演示了运行示例的计划提取。我们展示了相关组表达式的局部哈希表。每个本地哈希表将传入的优化请求映射到相应的子优化请求。

我们首先查找 req 的最佳组表达式。#1在根组，这导致了GatherMerge 操作符。Gath- erMerge 的本地哈希表中相应的子请求是 req #3。req #3的最佳组表达式是Sort。因此，我们将 GatherMerge 链接到 Sort。Sort 的局部哈希表中相应的子请求是 req #4。req #4 的最佳组表达式是 Inner-HashJoin[1,2]。因此，我们将 Sort 链接到 InnerHashJoin。按照相同的过程完成计划提取，最终得到图6所示的计划。

提取的计划以DXL格式序列化，并发送到数据库系统执行。数据库系统中的DXL2Plan转换器基于底层查询执行框 架将DXL计划转换为可执行计划。

多阶段优化。我们在Orca正在进行的工作包括实现多阶段优化。一个理想的

![img](https://pic3.zhimg.com/80/v2-fdefc913eadcaee8e77588e311c745b6_720w.webp)

![img](https://pic3.zhimg.com/80/v2-f5c80b6a7aa21cf257a28f08007dc5f2_720w.webp)

Orca 的mization 阶段被定义为一个完整的优化工作流，使用转换规则子集和(可选的)超时和成本阈值。当满足以下任一条件时，阶段终止:(1)找到了成本低于成本阈值的计划，(2)出现超时，或(3)耗尽了转换规则的子集。用户可以通过 Orca 的配置给出优化阶段的具体说明。这种技术允许资源受限的优化，例如，将最昂贵的转换规则配置为在后期运行，以避免增加优化时间。这种技术也是尽早获得查询计划以减少复杂查询的搜索空间的基础。查询执行。最终计划的副本被分发到每个部分。在分布式查询执行期间，每个段上的分布式强制执行器充当数据的发 送 者 和 接 收 者 。例 如 ，在 段 S 上 运 行 的Redistribute(T2.b)实例根据T2的哈希值将S上的元组发送给其他段。也从其他段上的其他 Redistribute(T2.b)实例接收元组。

### **4.2 并行查询优化**

查询优化可能是数据库系统中最消耗cpu的过程。cpu的有效使用延迟可以提供更好的查询计划，从而提高系统性能。并行 查询优化器对于从高级 CPU设计中获益至关重要，这些设计利用了越来越多的内核。

Orca 是一个多核优化器。优化过程被分解成小的工作单元，称为优化工作。Orca目前有七种不同类型的优化工作:

- Exp(g): Generate logically equivalent expressions of allgroup expressions in group g.
- Exp(gexpr): Generate logically equivalent expressions of a group expression gexpr.
- Imp(g): Generate implementations of all group expres-sions in group g.
- Imp(gexpr): Generate implementation alternatives of a group expression gexpr.
- Opt(g, req): Return the plan with the least estimated cost that is rooted by an operator in group g and sat-isﬁes optimization request req.
- Opt(gexpr, req): Return the plan with the least esti-mated cost that is rooted by gexpr and satisﬁes opti-mization request req.
- Xform(gexpr, t) Transform group expression gexpr us-ing rule t.

对于给定的查询，可能会创建每个类型的数百甚至数千个作业实例。这为处理作业依赖关系带来了挑战。例如，在对组表达式的子组也进行优化之前，不能对其进行优化图8显示了一个部分作业图，其中在优化请求 req0下对组g0 的优化触发了一个依赖作业的深度树。依赖被编码为子-父链接;父任务不能在子任务完成之前完成。虽然孩子的工作正在进行，但父母的工作需要暂停。这允许子任务在不依赖于其他任务的情况下，获取可用的线程并并行运行。当所有子作业完成时，将通知暂停的父作业恢复处理。

![img](https://pic2.zhimg.com/80/v2-f734045cb1c671abfdffddd313964e61_720w.webp)

Orca包含一个专门的作业调度器，它从头开始设计，以最大化作业的扇出依赖关系图，并为并行查询提供所需的基础设施优化调度器提供 api 来将优化作业定义为可重入过程，可用的处理线程可以拾取这些过程。它还维护作业依赖关系图，以识别并行的机会(例如，在不同的组中运行转换)，并在它们所依赖的作业终止时通知被暂停的作业。

在并行查询优化过程中，不同的优化请求可能会触发多个修改Memo组的并发请求。为了最小化具有相同目标的作业之间的同步开销(例如，探索同一组作业)，作业不应该知道彼此的存在。当一个具有某些目标的优化作业正在处理时，所有其他具有相同目标的传入作业将被迫等待，直到收到关于正在运行的作业完成的通知。此时，暂停的作业可以获取已完成作业的结果。通过将作业队列附加到每个组来启用此功能，只要存在具有相同目标的活动作业，就将传入的作业排队。

### **5.元数据交换**

Orca 被设计用于数据库系统之外的工作。优化器和数据库系统之间的一个主要交互点是元数据交换。例如，优化器可能需要知道给定表上是否定义了索引，以设计有效的查询计划。元数据的访问由一组元数据提供者(metadata provider)提供，这些提供者是用于从数据库系统检索元数据的特定于系统的插件。图9显示了Orca如何与不同的后端系统交换元数据。在查询优化期间，Orca访问的所有元数据对象都固定在内存缓存中，在优化完成或抛出错误时解除固定。对元数据对象的所有访问都是通过MD访问器完成的，该访问器跟踪在优化会话中被访问的对象，并确保不再需要时释放这些对象。MD访问器还负责从外部MD Provider 透明获取元数据，如果所请求的元数据对象不在缓存中。服务于不同优化会话的不同MD访问器可能有不同的获取元数据的外部MD提供程序。

除了系统特定的提供商外，Orca 还实现了一个基于文件的MD提供商来从DXL文件加载元数据，消除了访问活动后端系统的需要。Orca包含了一个自动化 的工具，可以将优化器需要的元数据收集到最小的 DXL文件中。在第 6.1 节中，我们将介绍如何在后端数据库系统离线时使用该工具重播客户查询的优化。

![img](https://pic3.zhimg.com/80/v2-83c8281b8d7de03e6e9ab0a49e846d06_720w.webp)

## **6. 可验证性**

测试查询优化器和构建查询优化器一样具有挑战性Orca 从早期开发阶段就开始考虑测试。有一个内置的测试方案，它使得开发人员很难引入回归作为添加新特性的一部分，并且使得测试工程师在每个构建中添加要验证的测试用例变得简单。此外，我们还利用了我们所构建的几个工具和测试框架来确保Orca的质量和可验证性，包括一个基数估计测试框架、多个不同规模的基准测试、一个可以通过逆转数据库统计数据[24]来生成数据的数据生成器，以及我们接下来将要讨论的两个独特的测试工具。

第一个工具(在第6.1节中讨论)是自动捕获和重播优化器的异常。第6.2 节讨论的第二个工具实现了一种自动化的方法来测量优化器成本模型的准确性。

### **6.1 最小上报**

AMPERe是一个自动捕获最小可移植和可执行Repros的工具。构建AMPERe的动机是能够复制和调试焦点在没有访问客户生产系统的情况下，优化器中的Tomer问题。

![img](https://pic1.zhimg.com/80/v2-5be62476cb244c905143638d6984f008_720w.webp)

当遇到意外错误时，会自动触发一个AMPERe转储，但也可以根据需要生成一个AMPERe转储，以调查不太理想的查询计划。转储捕获重现问题所需的最小数量的数据，包括在DXL中序列化的输入查询、优化器配置和元数据(参考第 3 节)。如果转储是由于异常而生成的，它还包括异常的堆栈跟踪。

清单2 显示了一个简化的AMPERe转储示例。转储只包含重现问题所需的数据。例如，转储捕获MD Cache的状态，其中只包含查询优化过程中获得的元数据。AMPERe 也是可扩展的。Orca中的任何组件都可以向AMPERe序列化器注册自己，从而在输出转储文件中生成额外的信息。

AMPERe 允许在生成转储的系统之外重放转储。任何Orca 实例都可以加载转储来检索输入查询、元数据和配置参数，以便调用与触发当前问题情形相同的优化会话。图10描述了这个过程，其中优化器从转储加载输入查询，为元数据创建基于文件的MD Provider，设置优化器的配置，然后生成优化线程以立即重现问题。

AMPERe还用作测试框架，其中转储充当包含输入查询及其预期计划的测试用例。回放转储文件时，奥卡可能会生成与预期不同的计划(例如，由于成本模型的更 改)。这样的差异会导致测试用例失败，并引发对计划差异的根本原因的调查。使用此框架，任何带有 AMPERe转储的bug，无论是由内部测试还是通过客户报告归档，都可以自动转换为一个自包含的测试用例。

### **6.2 优化器精度测试**

Orca 的成本模型的准确性会受到许多误差源的影响，包括不准确的基数估计和没有适当调整的成本模型参数。因此，成本模型为计划的执行提供了不完美的挂钟时间预测量化优化器的准确性对于避免 bug修复和新添加的特性带来的性能倒退是至关重要的。

Orca包含一个名为TAQO[15]的内置工具，用于测试查询优化器的准确性。TAQO度量优化器的成本模型对任意两个给定计划进行正确排序的能力，也就是说，估计成本较高的计划确实会运行更长时间。例如，在图 11中，优化器的顺序(p1， p3)，因为它们的实际成本与估算成本成正比。 另一方面，优化器命令(p1， p2)，因为它们的实际成本与估算成本成反比。

TAQO通过计算和执行优化器在优化给定查询时考虑的计划来度量优化器的准确性。一般来说，在搜索空间中评估单个计划是不可行的。这一限制可以通过从搜索空间统一采样计划来克服。优化请求的链接结构(参见4.1节)提供了TAQO用于基于[29]中引入的方法构建统一计划采样器的基础设施。

给定查询的搜索空间中的计划样本，TAQO计算基于估计成本的抽样计划排名和基于实际成本的计划排名之间的相关性得分。相关性得分结合了许多衡量指标，包括计划的重要性(对于非常好的计划的成本估计错误，该得分会惩罚优化器更多)，以及计划之间的距离(对于计划的估计成本在实际执行时间上接近的情况，该得分不会惩罚优化器)。相关评分还允许对不同数据库系统的优化器进行基准测试以评估它们的相对质量。我们在[15]中更详细地讨论了TAQO中实现的测试方法。